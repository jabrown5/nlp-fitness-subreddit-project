{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "underlying-jackson",
   "metadata": {},
   "source": [
    "# Data Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-graduation",
   "metadata": {},
   "source": [
    "This file contains the functions used to scrape and do prelimary clean-up during the compilation process. The python requests libary was used to complete this task.\n",
    "\n",
    "**In this file are the functions:**\n",
    "\n",
    "- scraper()\n",
    "    - This function actual scrapes the data. It takes in which subreddit's submissions to pull.  It also takes in the 'last batch' or the file that was just scraped as it uses the last row of it to determine what date to look at in order to begin its next iteration of the scraping process.  This function also specifies what parameters to use when scraping and specifies the subreddit, the number of rows to scrape, excluding of video content, and excluding anything authored by reddit's AutoModerator.\n",
    "    \n",
    "- compiler()\n",
    "    - This function takes in which subreddit to examine and the maximum number of posts to scrape. It creates an empty list to store all scraped posts and also sets a variable to hold the most recent scrape of 100 posts.  It is built around a while loop and continues to call the scraper() function until it has met the maximum numbers of posts. It adds each batch of 100 posts to the larger list of all posts and then returns a list of all posts once the maximum as been met.  Additionally, this function uses the time.sleep() function which allows for a more 'natural' or less robotic scrape of reddit.  It was important to include this so as not to overwhelm reddit's pushshift API.\n",
    "        \n",
    "- compile_scrapes()\n",
    "    - This function completes some very preliminary cleaning by removing postings that were deleted by a moderator, the user, or reddit. It also only keeps posts with content in the selftext column.  Lastly, it merges the bodyweightfitness and weightlifing scrapes into one dataframe which was then exported to be used in future steps.\n",
    "        \n",
    "        \n",
    "**In total, 20,000 posts were scraped from each subreddit. After merging the data and removing posts that had been flagged as deleted, the combined total of 40,000 posts had been reduced to 26,049 (weightlifting: 12,028, bodyweightfitness: 14,021).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spread-explorer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import random\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "import math\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-memorabilia",
   "metadata": {},
   "source": [
    "### Gather data using the requests library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "boolean-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "\n",
    "# Function built to perform multiple scrapes of the apishift reddit api\n",
    "# It will initiate a new scrape based on the date of the last post pulled\n",
    "# from the immediately prior scrape\n",
    "# HELP: https://reddit-api.readthedocs.io/en/latest/#searching-submissions\n",
    "# HELP: https://www.textjuicer.com/2019/07/crawling-all-submissions-from-a-subreddit/\n",
    "\n",
    "# This function does the scraping\n",
    "def scraper(subreddit, last_batch):\n",
    "    # setting up params to indicate what subreddit\n",
    "    # size (max is 100)\n",
    "    # excluding videos, posts created by automoderator\n",
    "    params = {\n",
    "    'subreddit' : subreddit,\n",
    "    'size' : 100,\n",
    "    'is_video': False,\n",
    "    'author': '!AutoModerator'\n",
    "    }\n",
    "    \n",
    "    # if the last_batch of scraped submissions is NOT blank / NoneType:\n",
    "    if last_batch != None:\n",
    "        # Find the last row of the most recent scrape to pull the \n",
    "        # UTC time in order to know where to initiate the next scrape\n",
    "        if len(last_batch) > 0:\n",
    "            # creating the param 'before' = to be included in request.get call below\n",
    "            # this calculates the utc date of the very last post of the most recent scrape\n",
    "            params['before'] = last_batch[-1]['created_utc']\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    # Make the request with url and params that have been updated for each scrape    \n",
    "    res = requests.get(url, params)\n",
    "    # return json data which will be added to post_list in compiler() below\n",
    "    return res.json()['data']\n",
    "\n",
    "# this function stores the scraped data and controls the intervals\n",
    "# at which scraper() is run\n",
    "def compiler(subreddit, posts_to_scrape):\n",
    "\n",
    "    # creating a list to store retrieved posts\n",
    "    post_list = []\n",
    "    \n",
    "    # setting up a list to hold the scraped posts from the \n",
    "    # most recent post scrape interation\n",
    "    # initially set to a NoneType object\n",
    "    last_batch = None\n",
    "\n",
    "    # settinq up while loop that will run as long as last_batch is NOT blank\n",
    "    # AND while the length of the post_list is still less than the number\n",
    "    # of desired posts to scrape\n",
    "    while last_batch != [] and len(post_list) < posts_to_scrape:\n",
    "        # calling the scraper() function and saving it as last_batch\n",
    "        last_batch = scraper(subreddit, last_batch)\n",
    "        # adding the most recent batch of scraped submissions to the\n",
    "        # larger post_list list\n",
    "        post_list = post_list + last_batch\n",
    "        # setting up .sleep() to randomly pick a wait time so\n",
    "        # scrape seems more 'natural'\n",
    "        # understanding time.sleep(): https://www.datacamp.com/community/tutorials/python-time-sleep\n",
    "        time.sleep(random.randint(3,7))\n",
    "    # return the post_list from the 0th row to the max # of posts requested    \n",
    "    return post_list[:posts_to_scrape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abandoned-million",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function built to compile and merge dataframes from two subreddits\n",
    "def compile_scrapes(df1, df2):\n",
    "    \n",
    "    # Turning scraped data into dataframes\n",
    "    df1 = pd.DataFrame(df1)\n",
    "    df2 = pd.DataFrame(df2)\n",
    "    # combining the two scrapes into one dataframe\n",
    "    df = pd.concat([df1, df2], axis=0, sort=False)\n",
    "\n",
    "    # dropping posts that have been removed via a\n",
    "    # moderator, user deleted, or by reddit\n",
    "    df = df[df['removed_by_category'] != 'moderator' ]\n",
    "    df = df[df['removed_by_category'] != 'deleted' ]\n",
    "    df = df[df['removed_by_category'] != 'reddit' ]\n",
    "    \n",
    "    # keeping only posts with text in selftext\n",
    "    df = df.loc[df['selftext'].str.len() > 0]\n",
    "\n",
    "    # Exporting the compiled dataframe\n",
    "    export_df = df.to_csv('../data/compiled_final2.csv', index = False) \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "moral-reaction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 68)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping the first subreddit of interest\n",
    "# and returning a dataframe\n",
    "df1 = compiler('bodyweightfitness', 150)\n",
    "df1 = pd.DataFrame(df1)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "rotary-concentration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 78)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping the second subreddit of interest\n",
    "# and returning a dataframe\n",
    "df2 = compiler('weightlifting', 145)\n",
    "df2 = pd.DataFrame(df2)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "intimate-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the compile_scrapes() to complete merge and do initial deletions\n",
    "final_df = compile_scrapes(df1, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "israeli-saying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26049, 107)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "imported-greek",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>allow_live_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_type</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>author_patreon_flair</th>\n",
       "      <th>author_premium</th>\n",
       "      <th>awarders</th>\n",
       "      <th>can_mod_post</th>\n",
       "      <th>contest_mode</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>domain</th>\n",
       "      <th>full_link</th>\n",
       "      <th>gildings</th>\n",
       "      <th>id</th>\n",
       "      <th>is_crosspostable</th>\n",
       "      <th>is_meta</th>\n",
       "      <th>is_original_content</th>\n",
       "      <th>is_reddit_media_domain</th>\n",
       "      <th>is_robot_indexable</th>\n",
       "      <th>is_self</th>\n",
       "      <th>is_video</th>\n",
       "      <th>link_flair_background_color</th>\n",
       "      <th>link_flair_richtext</th>\n",
       "      <th>link_flair_text_color</th>\n",
       "      <th>link_flair_type</th>\n",
       "      <th>locked</th>\n",
       "      <th>media_only</th>\n",
       "      <th>no_follow</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>num_crossposts</th>\n",
       "      <th>over_18</th>\n",
       "      <th>parent_whitelist_status</th>\n",
       "      <th>permalink</th>\n",
       "      <th>pinned</th>\n",
       "      <th>pwls</th>\n",
       "      <th>removed_by_category</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>send_replies</th>\n",
       "      <th>spoiler</th>\n",
       "      <th>stickied</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>subreddit_subscribers</th>\n",
       "      <th>subreddit_type</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>title</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>treatment_tags</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>url</th>\n",
       "      <th>whitelist_status</th>\n",
       "      <th>wls</th>\n",
       "      <th>post_hint</th>\n",
       "      <th>preview</th>\n",
       "      <th>author_flair_template_id</th>\n",
       "      <th>author_flair_text_color</th>\n",
       "      <th>author_flair_background_color</th>\n",
       "      <th>banned_by</th>\n",
       "      <th>crosspost_parent</th>\n",
       "      <th>crosspost_parent_list</th>\n",
       "      <th>url_overridden_by_dest</th>\n",
       "      <th>author_cakeday</th>\n",
       "      <th>edited</th>\n",
       "      <th>collections</th>\n",
       "      <th>suggested_sort</th>\n",
       "      <th>thumbnail_height</th>\n",
       "      <th>thumbnail_width</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>gilded</th>\n",
       "      <th>link_flair_template_id</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>link_flair_css_class</th>\n",
       "      <th>media</th>\n",
       "      <th>media_embed</th>\n",
       "      <th>secure_media</th>\n",
       "      <th>secure_media_embed</th>\n",
       "      <th>gallery_data</th>\n",
       "      <th>is_gallery</th>\n",
       "      <th>media_metadata</th>\n",
       "      <th>poll_data</th>\n",
       "      <th>event_end</th>\n",
       "      <th>event_is_live</th>\n",
       "      <th>event_start</th>\n",
       "      <th>steward_reports</th>\n",
       "      <th>removed_by</th>\n",
       "      <th>updated_utc</th>\n",
       "      <th>og_description</th>\n",
       "      <th>og_title</th>\n",
       "      <th>rte_mode</th>\n",
       "      <th>author_id</th>\n",
       "      <th>archived</th>\n",
       "      <th>author_created_utc</th>\n",
       "      <th>can_gild</th>\n",
       "      <th>category</th>\n",
       "      <th>content_categories</th>\n",
       "      <th>hidden</th>\n",
       "      <th>quarantine</th>\n",
       "      <th>removal_reason</th>\n",
       "      <th>subreddit_name_prefixed</th>\n",
       "      <th>brand_safe</th>\n",
       "      <th>previous_visits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>Solfire</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'e': 'text', 't': 'Dam Son'}]</td>\n",
       "      <td>Dam Son</td>\n",
       "      <td>richtext</td>\n",
       "      <td>t2_37jve</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1615696693</td>\n",
       "      <td>self.bodyweightfitness</td>\n",
       "      <td>https://www.reddit.com/r/bodyweightfitness/com...</td>\n",
       "      <td>{}</td>\n",
       "      <td>m4o0zb</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>dark</td>\n",
       "      <td>text</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>/r/bodyweightfitness/comments/m4o0zb/sunday_sh...</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1615696704</td>\n",
       "      <td>1</td>\n",
       "      <td>**HEY YOU,**\\n\\nHave you taken any recent pics...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>bodyweightfitness</td>\n",
       "      <td>t5_2tf0a</td>\n",
       "      <td>2026376.0</td>\n",
       "      <td>public</td>\n",
       "      <td>self</td>\n",
       "      <td>Sunday Show Off - Because it's perfectly fine ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.reddit.com/r/bodyweightfitness/com...</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dark</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>teetee9</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_16171byh</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1615643440</td>\n",
       "      <td>self.bodyweightfitness</td>\n",
       "      <td>https://www.reddit.com/r/bodyweightfitness/com...</td>\n",
       "      <td>{}</td>\n",
       "      <td>m46noj</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>dark</td>\n",
       "      <td>text</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>/r/bodyweightfitness/comments/m46noj/what_woul...</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1615643451</td>\n",
       "      <td>1</td>\n",
       "      <td>the context that led me to ask this question i...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>bodyweightfitness</td>\n",
       "      <td>t5_2tf0a</td>\n",
       "      <td>2025667.0</td>\n",
       "      <td>public</td>\n",
       "      <td>self</td>\n",
       "      <td>what would someone who is 5 foot tall and 114 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.reddit.com/r/bodyweightfitness/com...</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   all_awardings allow_live_comments   author author_flair_css_class  \\\n",
       "34            []               False  Solfire                   None   \n",
       "70            []               False  teetee9                   None   \n",
       "\n",
       "              author_flair_richtext author_flair_text author_flair_type  \\\n",
       "34  [{'e': 'text', 't': 'Dam Son'}]           Dam Son          richtext   \n",
       "70                               []              None              text   \n",
       "\n",
       "   author_fullname author_patreon_flair author_premium awarders  can_mod_post  \\\n",
       "34        t2_37jve                False          False       []         False   \n",
       "70     t2_16171byh                False          False       []         False   \n",
       "\n",
       "    contest_mode  created_utc                  domain  \\\n",
       "34         False   1615696693  self.bodyweightfitness   \n",
       "70         False   1615643440  self.bodyweightfitness   \n",
       "\n",
       "                                            full_link gildings      id  \\\n",
       "34  https://www.reddit.com/r/bodyweightfitness/com...       {}  m4o0zb   \n",
       "70  https://www.reddit.com/r/bodyweightfitness/com...       {}  m46noj   \n",
       "\n",
       "    is_crosspostable is_meta is_original_content  is_reddit_media_domain  \\\n",
       "34              True   False               False                   False   \n",
       "70              True   False               False                   False   \n",
       "\n",
       "   is_robot_indexable  is_self  is_video link_flair_background_color  \\\n",
       "34               True     True     False                               \n",
       "70               True     True     False                               \n",
       "\n",
       "   link_flair_richtext link_flair_text_color link_flair_type  locked  \\\n",
       "34                  []                  dark            text   False   \n",
       "70                  []                  dark            text   False   \n",
       "\n",
       "   media_only no_follow  num_comments  num_crossposts  over_18  \\\n",
       "34      False      True            43               0    False   \n",
       "70      False      True             3               0    False   \n",
       "\n",
       "   parent_whitelist_status                                          permalink  \\\n",
       "34                 all_ads  /r/bodyweightfitness/comments/m4o0zb/sunday_sh...   \n",
       "70                 all_ads  /r/bodyweightfitness/comments/m46noj/what_woul...   \n",
       "\n",
       "    pinned  pwls removed_by_category  retrieved_on  score  \\\n",
       "34   False   6.0                 NaN    1615696704      1   \n",
       "70   False   6.0                 NaN    1615643451      1   \n",
       "\n",
       "                                             selftext send_replies  spoiler  \\\n",
       "34  **HEY YOU,**\\n\\nHave you taken any recent pics...         True    False   \n",
       "70  the context that led me to ask this question i...         True    False   \n",
       "\n",
       "    stickied          subreddit subreddit_id  subreddit_subscribers  \\\n",
       "34      True  bodyweightfitness     t5_2tf0a              2026376.0   \n",
       "70     False  bodyweightfitness     t5_2tf0a              2025667.0   \n",
       "\n",
       "   subreddit_type thumbnail  \\\n",
       "34         public      self   \n",
       "70         public      self   \n",
       "\n",
       "                                                title  total_awards_received  \\\n",
       "34  Sunday Show Off - Because it's perfectly fine ...                    0.0   \n",
       "70  what would someone who is 5 foot tall and 114 ...                    0.0   \n",
       "\n",
       "   treatment_tags  upvote_ratio  \\\n",
       "34             []           1.0   \n",
       "70             []           1.0   \n",
       "\n",
       "                                                  url whitelist_status  wls  \\\n",
       "34  https://www.reddit.com/r/bodyweightfitness/com...          all_ads  6.0   \n",
       "70  https://www.reddit.com/r/bodyweightfitness/com...          all_ads  6.0   \n",
       "\n",
       "   post_hint preview author_flair_template_id author_flair_text_color  \\\n",
       "34       NaN     NaN                      NaN                    dark   \n",
       "70       NaN     NaN                      NaN                     NaN   \n",
       "\n",
       "   author_flair_background_color banned_by crosspost_parent  \\\n",
       "34                                     NaN              NaN   \n",
       "70                           NaN       NaN              NaN   \n",
       "\n",
       "   crosspost_parent_list url_overridden_by_dest author_cakeday  edited  \\\n",
       "34                   NaN                    NaN            NaN     NaN   \n",
       "70                   NaN                    NaN            NaN     NaN   \n",
       "\n",
       "   collections suggested_sort  thumbnail_height  thumbnail_width  \\\n",
       "34         NaN            NaN               NaN              NaN   \n",
       "70         NaN            NaN               NaN              NaN   \n",
       "\n",
       "   distinguished  gilded link_flair_template_id link_flair_text  \\\n",
       "34           NaN     NaN                    NaN             NaN   \n",
       "70           NaN     NaN                    NaN             NaN   \n",
       "\n",
       "   link_flair_css_class media media_embed secure_media secure_media_embed  \\\n",
       "34                  NaN   NaN         NaN          NaN                NaN   \n",
       "70                  NaN   NaN         NaN          NaN                NaN   \n",
       "\n",
       "   gallery_data is_gallery media_metadata poll_data  event_end event_is_live  \\\n",
       "34          NaN        NaN            NaN       NaN        NaN           NaN   \n",
       "70          NaN        NaN            NaN       NaN        NaN           NaN   \n",
       "\n",
       "    event_start steward_reports removed_by  updated_utc og_description  \\\n",
       "34          NaN             NaN        NaN          NaN            NaN   \n",
       "70          NaN             NaN        NaN          NaN            NaN   \n",
       "\n",
       "   og_title rte_mode author_id archived  author_created_utc can_gild  \\\n",
       "34      NaN      NaN       NaN      NaN                 NaN      NaN   \n",
       "70      NaN      NaN       NaN      NaN                 NaN      NaN   \n",
       "\n",
       "    category  content_categories hidden quarantine  removal_reason  \\\n",
       "34       NaN                 NaN    NaN        NaN             NaN   \n",
       "70       NaN                 NaN    NaN        NaN             NaN   \n",
       "\n",
       "   subreddit_name_prefixed brand_safe previous_visits  \n",
       "34                     NaN        NaN             NaN  \n",
       "70                     NaN        NaN             NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "pharmaceutical-artist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weightlifting        12028\n",
       "bodyweightfitness    14021\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['subreddit'].value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-hammer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
